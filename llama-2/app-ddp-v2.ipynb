{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "511d4035-de3d-4ec5-a90b-1657610c832e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'ok', 'restart': True}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import IPython\n",
    "IPython.Application.instance().kernel.do_shutdown(True) # \"True\" is to restart\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e18fa936-90a4-436d-a488-77b03f6a9e25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets==2.14.6 in /opt/app-root/lib/python3.9/site-packages (from -r requirements.txt (line 1)) (2.14.6)\n",
      "Requirement already satisfied: peft==0.4.0 in /opt/app-root/lib/python3.9/site-packages (from -r requirements.txt (line 2)) (0.4.0)\n",
      "Requirement already satisfied: torch==2.0.1 in /opt/app-root/lib/python3.9/site-packages (from -r requirements.txt (line 3)) (2.0.1)\n",
      "Requirement already satisfied: transformers==4.31.0 in /opt/app-root/lib/python3.9/site-packages (from -r requirements.txt (line 4)) (4.31.0)\n",
      "Requirement already satisfied: trl==0.4.7 in /opt/app-root/lib/python3.9/site-packages (from -r requirements.txt (line 5)) (0.4.7)\n",
      "Requirement already satisfied: scipy in /opt/app-root/lib/python3.9/site-packages (from -r requirements.txt (line 6)) (1.11.3)\n",
      "Requirement already satisfied: tiktoken in /opt/app-root/lib/python3.9/site-packages (from -r requirements.txt (line 7)) (0.5.1)\n",
      "Requirement already satisfied: bitsandbytes in /opt/app-root/lib/python3.9/site-packages (from -r requirements.txt (line 8)) (0.41.2.post2)\n",
      "Requirement already satisfied: accelerate in /opt/app-root/lib/python3.9/site-packages (from -r requirements.txt (line 9)) (0.24.1)\n",
      "Requirement already satisfied: multiprocess in /opt/app-root/lib/python3.9/site-packages (from datasets==2.14.6->-r requirements.txt (line 1)) (0.70.15)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/app-root/lib/python3.9/site-packages (from datasets==2.14.6->-r requirements.txt (line 1)) (6.0.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/app-root/lib/python3.9/site-packages (from datasets==2.14.6->-r requirements.txt (line 1)) (1.26.1)\n",
      "Requirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /opt/app-root/lib/python3.9/site-packages (from datasets==2.14.6->-r requirements.txt (line 1)) (2023.10.0)\n",
      "Requirement already satisfied: packaging in /opt/app-root/lib/python3.9/site-packages (from datasets==2.14.6->-r requirements.txt (line 1)) (23.1)\n",
      "Requirement already satisfied: pandas in /opt/app-root/lib/python3.9/site-packages (from datasets==2.14.6->-r requirements.txt (line 1)) (2.1.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /opt/app-root/lib/python3.9/site-packages (from datasets==2.14.6->-r requirements.txt (line 1)) (0.19.0)\n",
      "Requirement already satisfied: xxhash in /opt/app-root/lib/python3.9/site-packages (from datasets==2.14.6->-r requirements.txt (line 1)) (3.4.1)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /opt/app-root/lib/python3.9/site-packages (from datasets==2.14.6->-r requirements.txt (line 1)) (14.0.1)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /opt/app-root/lib/python3.9/site-packages (from datasets==2.14.6->-r requirements.txt (line 1)) (0.3.7)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/app-root/lib/python3.9/site-packages (from datasets==2.14.6->-r requirements.txt (line 1)) (2.31.0)\n",
      "Requirement already satisfied: aiohttp in /opt/app-root/lib/python3.9/site-packages (from datasets==2.14.6->-r requirements.txt (line 1)) (3.8.5)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /opt/app-root/lib/python3.9/site-packages (from datasets==2.14.6->-r requirements.txt (line 1)) (4.66.1)\n",
      "Requirement already satisfied: safetensors in /opt/app-root/lib/python3.9/site-packages (from peft==0.4.0->-r requirements.txt (line 2)) (0.4.0)\n",
      "Requirement already satisfied: psutil in /opt/app-root/lib/python3.9/site-packages (from peft==0.4.0->-r requirements.txt (line 2)) (5.9.5)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /opt/app-root/lib/python3.9/site-packages (from torch==2.0.1->-r requirements.txt (line 3)) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /opt/app-root/lib/python3.9/site-packages (from torch==2.0.1->-r requirements.txt (line 3)) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /opt/app-root/lib/python3.9/site-packages (from torch==2.0.1->-r requirements.txt (line 3)) (11.7.91)\n",
      "Requirement already satisfied: networkx in /opt/app-root/lib/python3.9/site-packages (from torch==2.0.1->-r requirements.txt (line 3)) (3.2.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /opt/app-root/lib/python3.9/site-packages (from torch==2.0.1->-r requirements.txt (line 3)) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /opt/app-root/lib/python3.9/site-packages (from torch==2.0.1->-r requirements.txt (line 3)) (10.2.10.91)\n",
      "Requirement already satisfied: sympy in /opt/app-root/lib/python3.9/site-packages (from torch==2.0.1->-r requirements.txt (line 3)) (1.12)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /opt/app-root/lib/python3.9/site-packages (from torch==2.0.1->-r requirements.txt (line 3)) (10.9.0.58)\n",
      "Requirement already satisfied: triton==2.0.0 in /opt/app-root/lib/python3.9/site-packages (from torch==2.0.1->-r requirements.txt (line 3)) (2.0.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/app-root/lib/python3.9/site-packages (from torch==2.0.1->-r requirements.txt (line 3)) (4.7.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /opt/app-root/lib/python3.9/site-packages (from torch==2.0.1->-r requirements.txt (line 3)) (11.7.99)\n",
      "Requirement already satisfied: jinja2 in /opt/app-root/lib/python3.9/site-packages (from torch==2.0.1->-r requirements.txt (line 3)) (3.1.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /opt/app-root/lib/python3.9/site-packages (from torch==2.0.1->-r requirements.txt (line 3)) (2.14.3)\n",
      "Requirement already satisfied: filelock in /opt/app-root/lib/python3.9/site-packages (from torch==2.0.1->-r requirements.txt (line 3)) (3.13.1)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /opt/app-root/lib/python3.9/site-packages (from torch==2.0.1->-r requirements.txt (line 3)) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /opt/app-root/lib/python3.9/site-packages (from torch==2.0.1->-r requirements.txt (line 3)) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /opt/app-root/lib/python3.9/site-packages (from torch==2.0.1->-r requirements.txt (line 3)) (11.7.101)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/app-root/lib/python3.9/site-packages (from transformers==4.31.0->-r requirements.txt (line 4)) (2023.10.3)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/app-root/lib/python3.9/site-packages (from transformers==4.31.0->-r requirements.txt (line 4)) (0.13.3)\n",
      "Requirement already satisfied: wheel in /opt/app-root/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1->-r requirements.txt (line 3)) (0.38.4)\n",
      "Requirement already satisfied: setuptools in /opt/app-root/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1->-r requirements.txt (line 3)) (53.0.0)\n",
      "Requirement already satisfied: cmake in /opt/app-root/lib/python3.9/site-packages (from triton==2.0.0->torch==2.0.1->-r requirements.txt (line 3)) (3.27.7)\n",
      "Requirement already satisfied: lit in /opt/app-root/lib/python3.9/site-packages (from triton==2.0.0->torch==2.0.1->-r requirements.txt (line 3)) (17.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/app-root/lib/python3.9/site-packages (from aiohttp->datasets==2.14.6->-r requirements.txt (line 1)) (1.9.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/app-root/lib/python3.9/site-packages (from aiohttp->datasets==2.14.6->-r requirements.txt (line 1)) (4.0.3)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/app-root/lib/python3.9/site-packages (from aiohttp->datasets==2.14.6->-r requirements.txt (line 1)) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/app-root/lib/python3.9/site-packages (from aiohttp->datasets==2.14.6->-r requirements.txt (line 1)) (6.0.4)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/app-root/lib/python3.9/site-packages (from aiohttp->datasets==2.14.6->-r requirements.txt (line 1)) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/app-root/lib/python3.9/site-packages (from aiohttp->datasets==2.14.6->-r requirements.txt (line 1)) (3.2.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/app-root/lib/python3.9/site-packages (from aiohttp->datasets==2.14.6->-r requirements.txt (line 1)) (1.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/app-root/lib/python3.9/site-packages (from requests>=2.19.0->datasets==2.14.6->-r requirements.txt (line 1)) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/app-root/lib/python3.9/site-packages (from requests>=2.19.0->datasets==2.14.6->-r requirements.txt (line 1)) (2023.7.22)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/app-root/lib/python3.9/site-packages (from requests>=2.19.0->datasets==2.14.6->-r requirements.txt (line 1)) (2.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/app-root/lib/python3.9/site-packages (from jinja2->torch==2.0.1->-r requirements.txt (line 3)) (2.1.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/app-root/lib/python3.9/site-packages (from pandas->datasets==2.14.6->-r requirements.txt (line 1)) (2023.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/app-root/lib/python3.9/site-packages (from pandas->datasets==2.14.6->-r requirements.txt (line 1)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/app-root/lib/python3.9/site-packages (from pandas->datasets==2.14.6->-r requirements.txt (line 1)) (2023.3.post1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/app-root/lib/python3.9/site-packages (from sympy->torch==2.0.1->-r requirements.txt (line 3)) (1.3.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/app-root/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas->datasets==2.14.6->-r requirements.txt (line 1)) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fe69ef8-7a5a-4761-a234-363b232cda82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate in /opt/app-root/lib/python3.9/site-packages (0.24.1)\n",
      "Requirement already satisfied: bitsandbytes in /opt/app-root/lib/python3.9/site-packages (0.41.2.post2)\n",
      "Requirement already satisfied: huggingface-hub in /opt/app-root/lib/python3.9/site-packages (from accelerate) (0.19.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/app-root/lib/python3.9/site-packages (from accelerate) (1.26.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in /opt/app-root/lib/python3.9/site-packages (from accelerate) (2.0.1)\n",
      "Requirement already satisfied: pyyaml in /opt/app-root/lib/python3.9/site-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: psutil in /opt/app-root/lib/python3.9/site-packages (from accelerate) (5.9.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/app-root/lib/python3.9/site-packages (from accelerate) (23.1)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /opt/app-root/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (10.2.10.91)\n",
      "Requirement already satisfied: networkx in /opt/app-root/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /opt/app-root/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /opt/app-root/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /opt/app-root/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /opt/app-root/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /opt/app-root/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (11.7.101)\n",
      "Requirement already satisfied: filelock in /opt/app-root/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /opt/app-root/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /opt/app-root/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (11.7.91)\n",
      "Requirement already satisfied: triton==2.0.0 in /opt/app-root/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (2.0.0)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /opt/app-root/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (11.7.4.91)\n",
      "Requirement already satisfied: typing-extensions in /opt/app-root/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (4.7.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /opt/app-root/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (11.7.99)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /opt/app-root/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (2.14.3)\n",
      "Requirement already satisfied: jinja2 in /opt/app-root/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: sympy in /opt/app-root/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: wheel in /opt/app-root/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.10.0->accelerate) (0.38.4)\n",
      "Requirement already satisfied: setuptools in /opt/app-root/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.10.0->accelerate) (53.0.0)\n",
      "Requirement already satisfied: cmake in /opt/app-root/lib/python3.9/site-packages (from triton==2.0.0->torch>=1.10.0->accelerate) (3.27.7)\n",
      "Requirement already satisfied: lit in /opt/app-root/lib/python3.9/site-packages (from triton==2.0.0->torch>=1.10.0->accelerate) (17.0.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/app-root/lib/python3.9/site-packages (from huggingface-hub->accelerate) (2023.10.0)\n",
      "Requirement already satisfied: requests in /opt/app-root/lib/python3.9/site-packages (from huggingface-hub->accelerate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/app-root/lib/python3.9/site-packages (from huggingface-hub->accelerate) (4.66.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/app-root/lib/python3.9/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/app-root/lib/python3.9/site-packages (from requests->huggingface-hub->accelerate) (3.2.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/app-root/lib/python3.9/site-packages (from requests->huggingface-hub->accelerate) (2023.7.22)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/app-root/lib/python3.9/site-packages (from requests->huggingface-hub->accelerate) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/app-root/lib/python3.9/site-packages (from requests->huggingface-hub->accelerate) (2.0.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/app-root/lib/python3.9/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install  accelerate bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2601458b-6bfd-4674-88cd-c9740308bb79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/app-root/lib64/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments, BitsAndBytesConfig\n",
    "from trl import SFTTrainer\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e2e6714-a94d-4362-a9e1-3c4f3c0fe11a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Available CUDA devices: ['cuda:0', 'cuda:1', 'cuda:2', 'cuda:3']\n"
     ]
    }
   ],
   "source": [
    "available_gpus = [f'cuda:{i}' for i in range(torch.cuda.device_count())]\n",
    "logger.info(f\"Available CUDA devices: {available_gpus}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14c241ab-46f8-49e4-a66a-77572874ce84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Dataset loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "data = load_dataset(\"tatsu-lab/alpaca\", split=\"train\")\n",
    "logger.info(\"Dataset loaded successfully.\")\n",
    "\n",
    "data = data.train_test_split(test_size=0.1)\n",
    "train_dataset = data[\"train\"]\n",
    "test_dataset = data[\"test\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "376f051d-c2b4-4a5d-9a06-9a8c0147a2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(query: str, model, tokenizer) -> str:\n",
    "  device = \"cuda:0\"\n",
    "\n",
    "  prompt_template = \"\"\"\n",
    "  Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
    "  ### Question:\n",
    "  {query}\n",
    "\n",
    "  ### Answer:\n",
    "  \"\"\"\n",
    "  prompt = prompt_template.format(query=query)\n",
    "\n",
    "  encodeds = tokenizer(prompt, return_tensors=\"pt\", add_special_tokens=True)\n",
    "\n",
    "  model_inputs = encodeds.to(device)\n",
    "\n",
    "\n",
    "  generated_ids = model.generate(**model_inputs, max_new_tokens=1000, do_sample=True, pad_token_id=tokenizer.eos_token_id)\n",
    "  decoded = tokenizer.batch_decode(generated_ids)\n",
    "  return (decoded[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c790879-73a0-426c-95b7-1bd458264bc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Tokenizer prepared successfully.\n"
     ]
    }
   ],
   "source": [
    "# Prepare tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"daryl149/llama-2-7b-chat-hf\", trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "logger.info(\"Tokenizer prepared successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e7bb0f4-3679-4a34-95ad-3832009ff80e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.99s/it]\n",
      "INFO:__main__:Model loaded and token embeddings resized successfully.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Prepare model for quantization and load pretrained weights\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "# current_device = 'cuda:0'\n",
    "# torch.cuda.set_device(current_device)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"daryl149/llama-2-7b-chat-hf\",\n",
    "    device_map = 'auto',\n",
    "    quantization_config=quantization_config,\n",
    ")\n",
    "\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "logger.info(\"Model loaded and token embeddings resized successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2919574a-e973-487f-94df-36ab4ea06210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> \n",
      "  Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "  ### Question:\n",
      "  Will capital gains affect my tax bracket?\n",
      "\n",
      "  ### Answer:\n",
      "   Yes, capital gains can affect your tax bracket. When you sell an investment for more than you paid for it, you have a capital gain. This gain is considered taxable income and can affect your tax bracket.\n",
      "   For example, let's say you sold an investment for $10,000 that you originally purchased for $5,000. Your capital gain is $5,000, which is taxable income. Depending on your other sources of income, this gain could bump you into a higher tax bracket, resulting in a higher tax liability.\n",
      "   However, it's worth noting that certain types of investments, such as those held for long-term (more than one year), may be eligible for lower capital gains tax rates. Additionally, some taxpayers may be eligible for capital gains tax exemptions or deductions, depending on their individual circumstances.\n",
      "   As with any tax-related question, it's always a good idea to consult with a tax professional or financial advisor to understand how capital gains could affect your specific tax situation.\n",
      "  Have any other questions?</s>\n"
     ]
    }
   ],
   "source": [
    "result = get_completion(query=\"Will capital gains affect my tax bracket?\", model=model, tokenizer=tokenizer)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6519a9c4-7c18-4603-a151-117c61265c9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:PEFT configuration prepared successfully.\n",
      "INFO:__main__:Training arguments: TrainingArguments(\n",
      "_n_gpu=4,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_backend=None,\n",
      "ddp_broadcast_buffers=None,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=False,\n",
      "do_predict=False,\n",
      "do_train=False,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_steps=None,\n",
      "evaluation_strategy=no,\n",
      "fp16=True,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "gradient_accumulation_steps=16,\n",
      "gradient_checkpointing=False,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=0.0002,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=0,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=llama-finetuned-7b2/runs/Nov09_22-33-04_genai-0,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=1,\n",
      "logging_strategy=steps,\n",
      "lr_scheduler_type=linear,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=100,\n",
      "metric_for_best_model=None,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=1,\n",
      "optim=paged_adamw_8bit,\n",
      "optim_args=None,\n",
      "output_dir=llama-finetuned-7b2,\n",
      "overwrite_output_dir=False,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=8,\n",
      "per_device_train_batch_size=2,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "report_to=[],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=llama-finetuned-7b2,\n",
      "save_on_each_node=False,\n",
      "save_safetensors=False,\n",
      "save_steps=500,\n",
      "save_strategy=steps,\n",
      "save_total_limit=3,\n",
      "seed=42,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.1,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      "xpu_backend=None,\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Prepare model for k-bit training\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "\n",
    "# Define PEFT configuration\n",
    "peft_config = LoraConfig(r=16, lora_alpha=32, lora_dropout=0.05, bias=\"none\", task_type=\"CAUSAL_LM\")\n",
    "model = get_peft_model(model, peft_config)\n",
    "logger.info(\"PEFT configuration prepared successfully.\")\n",
    "\n",
    "# Define training arguments\n",
    "use_fp16 = torch.cuda.is_available()\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"llama-finetuned-7b2\",\n",
    "    per_device_train_batch_size=2,\n",
    "    gradient_accumulation_steps=16,\n",
    "    optim=\"paged_adamw_8bit\",\n",
    "    max_steps=100,\n",
    "    logging_steps=1,\n",
    "    learning_rate=2e-4,\n",
    "    fp16=use_fp16,\n",
    "    warmup_ratio=0.1,\n",
    "    lr_scheduler_type=\"linear\",\n",
    "    num_train_epochs=1,\n",
    "    save_strategy=\"steps\",\n",
    "    save_total_limit=3,\n",
    "    push_to_hub=False,\n",
    ")\n",
    "logger.info(f\"Training arguments: {training_args}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ba3412-18d3-4044-be92-ac2295acdabd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:accelerate.utils.other:Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "/opt/app-root/lib64/python3.9/site-packages/trl/trainer/sft_trainer.py:212: UserWarning: You passed `packing=True` to the SFTTrainer, and you are training your model with `max_steps` strategy. The dataset will be iterated until the `max_steps` are reached.\n",
      "  warnings.warn(\n",
      "INFO:__main__:Trainer initialized successfully.\n",
      "INFO:__main__:Trainer arguments: <trl.trainer.sft_trainer.SFTTrainer object at 0x7f80114a36d0>\n",
      "INFO:__main__:Training started.\n",
      "You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 18/100 29:55 < 2:33:21, 0.01 it/s, Epoch 0.01/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.517700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.560800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.504700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.545800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.506200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.467400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.410600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.334400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.286100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.280100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.229800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.293100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1.244800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1.249400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.187600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>1.219400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Initialize the trainer\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=train_dataset,\n",
    "    dataset_text_field=\"text\",\n",
    "    max_seq_length=1024,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_args,\n",
    "    packing=True,\n",
    "    peft_config=peft_config,\n",
    ")\n",
    "logger.info(\"Trainer initialized successfully.\")\n",
    "logger.info(f\"Trainer arguments: {trainer}\")\n",
    "\n",
    "logger.info(\"Training started.\")\n",
    "trainer.train()\n",
    "logger.info(\"Training Complete.\")\n",
    "\n",
    "\n",
    "# The model and training progress will be automatically saved during training at the specified intervals.\n",
    "# Save the final model and tokenizer locally after training\n",
    "trainer.save_model(\"llama-finetuned-7b2_final_checkpoint\")\n",
    "tokenizer.save_pretrained(\"llama-finetuned-7b2_final_checkpoint\")\n",
    "logger.info(\"Final model and tokenizer saved locally.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "57345eec-2441-4ea4-8946-cf2b0dc1ec58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Thu Nov  9 22:20:56 2023       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  Tesla T4                       On  | 00000000:00:1B.0 Off |                    0 |\n",
      "| N/A   26C    P0              28W /  70W |  14780MiB / 15360MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla T4                       On  | 00000000:00:1C.0 Off |                    0 |\n",
      "| N/A   26C    P0              27W /  70W |   8962MiB / 15360MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla T4                       On  | 00000000:00:1D.0 Off |                    0 |\n",
      "| N/A   28C    P0              28W /  70W |   4416MiB / 15360MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla T4                       On  | 00000000:00:1E.0 Off |                    0 |\n",
      "| N/A   27C    P0              28W /  70W |   5416MiB / 15360MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d4055a-e299-4c59-b943-90d9dc292a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b4c8bf-9d94-4602-9fb5-1dd79973d3a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
